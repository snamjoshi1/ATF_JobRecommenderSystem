{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\myenvnew\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "E:\\Anaconda\\envs\\myenvnew\\lib\\site-packages\\gensim\\matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import pyLDAvis\n",
    "sns.set()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import gensim\n",
    "\n",
    "\n",
    "# import nltk\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1057 entries, 0 to 1056\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   bio                 1057 non-null   object\n",
      " 1   word_tokenized      1057 non-null   object\n",
      " 2   sentence_tokenized  1057 non-null   object\n",
      " 3   word_count          1057 non-null   int64 \n",
      " 4   sentence_count      1057 non-null   int64 \n",
      " 5   clean_words         1057 non-null   object\n",
      " 6   clean_stemmed       1057 non-null   object\n",
      " 7   clean_lemmed        1057 non-null   object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 66.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/pande/Capstone/Profiles/data/df_processed_bio.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year old', 269),\n",
       " ('locomotor disability', 153),\n",
       " ('data entry', 110),\n",
       " ('hearing impairment', 89),\n",
       " ('charitable trust', 85),\n",
       " ('ratna nidhi', 81),\n",
       " ('nidhi charitable', 78),\n",
       " ('ratna nidhi charitable', 78),\n",
       " ('nidhi charitable trust', 78),\n",
       " ('ratna nidhi charitable trust', 78)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the transform\n",
    "vectorizer = CountVectorizer(stop_words = 'english', max_df = 0.75,ngram_range=(2, 4))\n",
    "# tokenize and build vocab\n",
    "bag_of_words = vectorizer.fit_transform(df.clean_lemmed)\n",
    "# summarize\n",
    "sum_words = bag_of_words.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "words_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1057x115650 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 148392 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5379 documents represented as a 14,409 dimensional vector (14,409 words)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA.fit(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([94889, 94888, 94890, 60601, 18219, 85334, 85335, 85336, 70855,\n",
       "       70854], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topic_words = first_topic.argsort()[-10:]\n",
    "top_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\myenvnew\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skilled ratna nidhi\n",
      "skilled ratna\n",
      "skilled ratna nidhi charitable\n",
      "locomotor disability\n",
      "charitable trust\n",
      "ratna nidhi\n",
      "ratna nidhi charitable\n",
      "ratna nidhi charitable trust\n",
      "nidhi charitable trust\n",
      "nidhi charitable\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:\n",
    "    print(vectorizer.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['skilled ratna nidhi', 'skilled ratna', 'skilled ratna nidhi charitable', 'locomotor disability', 'charitable trust', 'ratna nidhi', 'ratna nidhi charitable', 'ratna nidhi charitable trust', 'nidhi charitable trust', 'nidhi charitable']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['best ability', 'spectrum disorder', 'autism spectrum disorder', 'looking opportunity', 'sign language', 'currently working', 'autism spectrum', 'hearing impairment', 'west bengal', 'year old']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['course american', 'banking product', 'banking product like', 'insurance home', 'completed month training', 'completed month', 'type banking', 'soft skill', 'month training', 'year old']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['month completed education', 'old candidate', 'year old candidate', 'polio age month', 'completed education', 'age month', 'affected polio age', 'affected polio', 'polio age', 'year old']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['training trrain', 'andhra pradesh', 'completed ssc', 'trrain organization', 'locomotor disability completed', 'computer knowledge', 'basic computer', 'disability completed', 'locomotor disability', 'year old']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1057, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values = LDA.transform(bag_of_words)\n",
    "topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Topic'] = topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bio</th>\n",
       "      <th>word_tokenized</th>\n",
       "      <th>sentence_tokenized</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>clean_words</th>\n",
       "      <th>clean_stemmed</th>\n",
       "      <th>clean_lemmed</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ratul arora is from delhi. he has blindness. h...</td>\n",
       "      <td>['ratul', 'arora', 'is', 'from', 'delhi', 'he'...</td>\n",
       "      <td>['ratul arora is from delhi.', 'he has blindne...</td>\n",
       "      <td>105</td>\n",
       "      <td>9</td>\n",
       "      <td>['ratul', 'arora', 'delhi', 'blindness', 'hold...</td>\n",
       "      <td>['ratul', 'arora', 'delhi', 'blind', 'hold', '...</td>\n",
       "      <td>['ratul', 'arora', 'delhi', 'blindness', 'hold...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aman verma is from nalasopara, maharashtra. he...</td>\n",
       "      <td>['aman', 'verma', 'is', 'from', 'nalasopara', ...</td>\n",
       "      <td>['aman verma is from nalasopara, maharashtra.'...</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>['aman', 'verma', 'nalasopara', 'maharashtra',...</td>\n",
       "      <td>['aman', 'verma', 'nalasopara', 'maharashtra',...</td>\n",
       "      <td>['aman', 'verma', 'nalasopara', 'maharashtra',...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sampa gupta is from mumbai, maharashtra. she h...</td>\n",
       "      <td>['sampa', 'gupta', 'is', 'from', 'mumbai', 'ma...</td>\n",
       "      <td>['sampa gupta is from mumbai, maharashtra.', '...</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "      <td>['sampa', 'gupta', 'mumbai', 'maharashtra', 'b...</td>\n",
       "      <td>['sampa', 'gupta', 'mumbai', 'maharashtra', 'b...</td>\n",
       "      <td>['sampa', 'gupta', 'mumbai', 'maharashtra', 'b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>monu varma is a 29-year-old visually impaired ...</td>\n",
       "      <td>['monu', 'varma', 'is', 'a', '29', 'year', 'ol...</td>\n",
       "      <td>['monu varma is a 29-year-old visually impaire...</td>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "      <td>['monu', 'varma', '29', 'year', 'old', 'visual...</td>\n",
       "      <td>['monu', 'varma', '29', 'year', 'old', 'visual...</td>\n",
       "      <td>['monu', 'varma', '29', 'year', 'old', 'visual...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jayant singh raghav believes that the position...</td>\n",
       "      <td>['jayant', 'singh', 'raghav', 'believes', 'tha...</td>\n",
       "      <td>['jayant singh raghav believes that the positi...</td>\n",
       "      <td>214</td>\n",
       "      <td>12</td>\n",
       "      <td>['jayant', 'singh', 'raghav', 'believes', 'pos...</td>\n",
       "      <td>['jayant', 'singh', 'raghav', 'believ', 'posit...</td>\n",
       "      <td>['jayant', 'singh', 'raghav', 'belief', 'posit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 bio  \\\n",
       "0  ratul arora is from delhi. he has blindness. h...   \n",
       "1  aman verma is from nalasopara, maharashtra. he...   \n",
       "2  sampa gupta is from mumbai, maharashtra. she h...   \n",
       "3  monu varma is a 29-year-old visually impaired ...   \n",
       "4  jayant singh raghav believes that the position...   \n",
       "\n",
       "                                      word_tokenized  \\\n",
       "0  ['ratul', 'arora', 'is', 'from', 'delhi', 'he'...   \n",
       "1  ['aman', 'verma', 'is', 'from', 'nalasopara', ...   \n",
       "2  ['sampa', 'gupta', 'is', 'from', 'mumbai', 'ma...   \n",
       "3  ['monu', 'varma', 'is', 'a', '29', 'year', 'ol...   \n",
       "4  ['jayant', 'singh', 'raghav', 'believes', 'tha...   \n",
       "\n",
       "                                  sentence_tokenized  word_count  \\\n",
       "0  ['ratul arora is from delhi.', 'he has blindne...         105   \n",
       "1  ['aman verma is from nalasopara, maharashtra.'...         100   \n",
       "2  ['sampa gupta is from mumbai, maharashtra.', '...          84   \n",
       "3  ['monu varma is a 29-year-old visually impaire...          89   \n",
       "4  ['jayant singh raghav believes that the positi...         214   \n",
       "\n",
       "   sentence_count                                        clean_words  \\\n",
       "0               9  ['ratul', 'arora', 'delhi', 'blindness', 'hold...   \n",
       "1               7  ['aman', 'verma', 'nalasopara', 'maharashtra',...   \n",
       "2               6  ['sampa', 'gupta', 'mumbai', 'maharashtra', 'b...   \n",
       "3               5  ['monu', 'varma', '29', 'year', 'old', 'visual...   \n",
       "4              12  ['jayant', 'singh', 'raghav', 'believes', 'pos...   \n",
       "\n",
       "                                       clean_stemmed  \\\n",
       "0  ['ratul', 'arora', 'delhi', 'blind', 'hold', '...   \n",
       "1  ['aman', 'verma', 'nalasopara', 'maharashtra',...   \n",
       "2  ['sampa', 'gupta', 'mumbai', 'maharashtra', 'b...   \n",
       "3  ['monu', 'varma', '29', 'year', 'old', 'visual...   \n",
       "4  ['jayant', 'singh', 'raghav', 'believ', 'posit...   \n",
       "\n",
       "                                        clean_lemmed  Topic  \n",
       "0  ['ratul', 'arora', 'delhi', 'blindness', 'hold...      3  \n",
       "1  ['aman', 'verma', 'nalasopara', 'maharashtra',...      4  \n",
       "2  ['sampa', 'gupta', 'mumbai', 'maharashtra', 'b...      2  \n",
       "3  ['monu', 'varma', '29', 'year', 'old', 'visual...      1  \n",
       "4  ['jayant', 'singh', 'raghav', 'belief', 'posit...      4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
