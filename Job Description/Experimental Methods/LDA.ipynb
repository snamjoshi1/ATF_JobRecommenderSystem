{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\myenvnew\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "E:\\Anaconda\\envs\\myenvnew\\lib\\site-packages\\gensim\\matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import pyLDAvis\n",
    "sns.set()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import gensim\n",
    "\n",
    "\n",
    "# import nltk\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5379 entries, 0 to 5378\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Description         5379 non-null   object\n",
      " 1   lower_description   5379 non-null   object\n",
      " 2   word_tokenized      5379 non-null   object\n",
      " 3   sentence_tokenized  5379 non-null   object\n",
      " 4   word_count          5379 non-null   int64 \n",
      " 5   sentence_count      5379 non-null   int64 \n",
      " 6   clean_words         5379 non-null   object\n",
      " 7   clean_stemmed       5379 non-null   object\n",
      " 8   clean_lemmed        5379 non-null   object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 378.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:/Users/pande/Job-Description-Skills-Extractor/data/collected_data/df_description_processed.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('machine learning', 5219),\n",
       " ('year experience', 4067),\n",
       " ('data science', 3393),\n",
       " ('big data', 3053),\n",
       " ('computer science', 2885),\n",
       " ('data scientist', 2560),\n",
       " ('data analysis', 2069),\n",
       " ('communication skill', 1972),\n",
       " ('bachelor degree', 1966),\n",
       " ('experience working', 1897)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the transform\n",
    "vectorizer = CountVectorizer(stop_words = 'english', max_df = 0.75,ngram_range=(2, 4))\n",
    "# tokenize and build vocab\n",
    "bag_of_words = vectorizer.fit_transform(df.clean_lemmed)\n",
    "# summarize\n",
    "sum_words = bag_of_words.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "words_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5379x1876070 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3933900 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5379 documents represented as a 14,409 dimensional vector (14,409 words)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA.fit(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 396398,  656593,  167167,  675700,  434532,  189813,  432340,\n",
       "        328216, 1002591, 1869757], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topic_words = first_topic.argsort()[-10:]\n",
    "top_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\myenvnew\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data analysis\n",
      "experience data\n",
      "bachelor degree\n",
      "experience working\n",
      "data scientist\n",
      "big data\n",
      "data science\n",
      "computer science\n",
      "machine learning\n",
      "year experience\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:\n",
    "    print(vectorizer.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['data analysis', 'experience data', 'bachelor degree', 'experience working', 'data scientist', 'big data', 'data science', 'computer science', 'machine learning', 'year experience']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['experience working', 'communication skill', 'data analysis', 'data set', 'computer science', 'data scientist', 'big data', 'year experience', 'data science', 'machine learning']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['experience working', 'communication skill', 'data scientist', 'bachelor degree', 'data analysis', 'big data', 'computer science', 'data science', 'year experience', 'machine learning']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['experience working', 'data analysis', 'bachelor degree', 'communication skill', 'data scientist', 'computer science', 'data science', 'big data', 'year experience', 'machine learning']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['communication skill', 'bachelor degree', 'data analysis', 'data analytics', 'data scientist', 'year experience', 'computer science', 'big data', 'data science', 'machine learning']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5379, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values = LDA.transform(bag_of_words)\n",
    "topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Topic'] = topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>lower_description</th>\n",
       "      <th>word_tokenized</th>\n",
       "      <th>sentence_tokenized</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>clean_words</th>\n",
       "      <th>clean_stemmed</th>\n",
       "      <th>clean_lemmed</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITION SUMMARY, The Business Analyst role is...</td>\n",
       "      <td>position summary, the business analyst role is...</td>\n",
       "      <td>['position', 'summary', 'the', 'business', 'an...</td>\n",
       "      <td>['POSITION SUMMARY, The Business Analyst role ...</td>\n",
       "      <td>424</td>\n",
       "      <td>25</td>\n",
       "      <td>['position', 'summary', 'business', 'analyst',...</td>\n",
       "      <td>['posit', 'summari', 'busi', 'analyst', 'role'...</td>\n",
       "      <td>['position', 'summary', 'business', 'analyst',...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do we need?, You to have an amazing perso...</td>\n",
       "      <td>what do we need?, you to have an amazing perso...</td>\n",
       "      <td>['what', 'do', 'we', 'need', 'you', 'to', 'hav...</td>\n",
       "      <td>['What do we need?, You to have an amazing per...</td>\n",
       "      <td>286</td>\n",
       "      <td>10</td>\n",
       "      <td>['need', 'amazing', 'personality', 'communicat...</td>\n",
       "      <td>['need', 'amaz', 'person', 'commun', 'style', ...</td>\n",
       "      <td>['need', 'amazing', 'personality', 'communicat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Validate, analyze, and conduct statistical ana...</td>\n",
       "      <td>validate, analyze, and conduct statistical ana...</td>\n",
       "      <td>['validate', 'analyze', 'and', 'conduct', 'sta...</td>\n",
       "      <td>['Validate, analyze, and conduct statistical a...</td>\n",
       "      <td>314</td>\n",
       "      <td>24</td>\n",
       "      <td>['validate', 'analyze', 'conduct', 'statistica...</td>\n",
       "      <td>['valid', 'analyz', 'conduct', 'statist', 'ana...</td>\n",
       "      <td>['validate', 'analyze', 'conduct', 'statistica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Full time, Washington, DC metro area, Starting...</td>\n",
       "      <td>full time, washington, dc metro area, starting...</td>\n",
       "      <td>['full', 'time', 'washington', 'dc', 'metro', ...</td>\n",
       "      <td>['Full time, Washington, DC metro area, Starti...</td>\n",
       "      <td>297</td>\n",
       "      <td>13</td>\n",
       "      <td>['full', 'time', 'washington', 'dc', 'metro', ...</td>\n",
       "      <td>['full', 'time', 'washington', 'dc', 'metro', ...</td>\n",
       "      <td>['full', 'time', 'washington', 'dc', 'metro', ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assist in consultations with business partners...</td>\n",
       "      <td>assist in consultations with business partners...</td>\n",
       "      <td>['assist', 'in', 'consultations', 'with', 'bus...</td>\n",
       "      <td>['Assist in consultations with business partne...</td>\n",
       "      <td>316</td>\n",
       "      <td>7</td>\n",
       "      <td>['assist', 'consultations', 'business', 'partn...</td>\n",
       "      <td>['assist', 'consult', 'busi', 'partner', 'inte...</td>\n",
       "      <td>['assist', 'consultation', 'business', 'partne...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0  POSITION SUMMARY, The Business Analyst role is...   \n",
       "1  What do we need?, You to have an amazing perso...   \n",
       "2  Validate, analyze, and conduct statistical ana...   \n",
       "3  Full time, Washington, DC metro area, Starting...   \n",
       "4  Assist in consultations with business partners...   \n",
       "\n",
       "                                   lower_description  \\\n",
       "0  position summary, the business analyst role is...   \n",
       "1  what do we need?, you to have an amazing perso...   \n",
       "2  validate, analyze, and conduct statistical ana...   \n",
       "3  full time, washington, dc metro area, starting...   \n",
       "4  assist in consultations with business partners...   \n",
       "\n",
       "                                      word_tokenized  \\\n",
       "0  ['position', 'summary', 'the', 'business', 'an...   \n",
       "1  ['what', 'do', 'we', 'need', 'you', 'to', 'hav...   \n",
       "2  ['validate', 'analyze', 'and', 'conduct', 'sta...   \n",
       "3  ['full', 'time', 'washington', 'dc', 'metro', ...   \n",
       "4  ['assist', 'in', 'consultations', 'with', 'bus...   \n",
       "\n",
       "                                  sentence_tokenized  word_count  \\\n",
       "0  ['POSITION SUMMARY, The Business Analyst role ...         424   \n",
       "1  ['What do we need?, You to have an amazing per...         286   \n",
       "2  ['Validate, analyze, and conduct statistical a...         314   \n",
       "3  ['Full time, Washington, DC metro area, Starti...         297   \n",
       "4  ['Assist in consultations with business partne...         316   \n",
       "\n",
       "   sentence_count                                        clean_words  \\\n",
       "0              25  ['position', 'summary', 'business', 'analyst',...   \n",
       "1              10  ['need', 'amazing', 'personality', 'communicat...   \n",
       "2              24  ['validate', 'analyze', 'conduct', 'statistica...   \n",
       "3              13  ['full', 'time', 'washington', 'dc', 'metro', ...   \n",
       "4               7  ['assist', 'consultations', 'business', 'partn...   \n",
       "\n",
       "                                       clean_stemmed  \\\n",
       "0  ['posit', 'summari', 'busi', 'analyst', 'role'...   \n",
       "1  ['need', 'amaz', 'person', 'commun', 'style', ...   \n",
       "2  ['valid', 'analyz', 'conduct', 'statist', 'ana...   \n",
       "3  ['full', 'time', 'washington', 'dc', 'metro', ...   \n",
       "4  ['assist', 'consult', 'busi', 'partner', 'inte...   \n",
       "\n",
       "                                        clean_lemmed  Topic  \n",
       "0  ['position', 'summary', 'business', 'analyst',...      3  \n",
       "1  ['need', 'amazing', 'personality', 'communicat...      4  \n",
       "2  ['validate', 'analyze', 'conduct', 'statistica...      0  \n",
       "3  ['full', 'time', 'washington', 'dc', 'metro', ...      2  \n",
       "4  ['assist', 'consultation', 'business', 'partne...      4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
